{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8725f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_token = '6534296374:AAEUeY4HcskIHDcjRjD6rgusZQkPmmO2IEk'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba11cb",
   "metadata": {},
   "source": [
    "### Чат бот для изучения возможностей \"затравочного\" программирования на основе rugpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ee845",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install update gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dialogflow gensim annoy tqdm stop_words pymorphy2 python-telegram-bot==13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandarallelb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b2feb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "#from gensim.models import Word2Vec, FastText\n",
    "\n",
    "\n",
    "from collections.abc import Mapping\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "    \n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f327d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2032b76a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#загрузка моделей из hugging face\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
    "gpt3_large = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
    "#gpt3_large = gpt3_large.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2760c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095c0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generated_text(text, model, tokenizer):\n",
    "\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "   \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(input_ids, \n",
    "                            do_sample=True,\n",
    "                            num_beams=3,\n",
    "                            temperature=0.8,\n",
    "                            top_p=0.5,\n",
    "                            max_length=55,\n",
    "                            pad_token_id=tokenizer.eos_token_id\n",
    "                            )\n",
    "    generated_text = list(map(tokenizer.decode, out))[0]\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53f7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(sentence, model, tokenizer, conatation, answer ):\n",
    "\n",
    "    ppl_values = []\n",
    "\n",
    "    for i in conatation:\n",
    "        encodings = tokenizer(i + ' ' + sentence, return_tensors='pt')\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "              outputs = gpt3_large(input_ids=input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        ppl = math.exp(loss.item() * input_ids.size(1))\n",
    "        ppl_values.append(ppl)\n",
    "     \n",
    "    n = min(enumerate(ppl_values),key=lambda x: x[1])[0] \n",
    "    return answer[n], n\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции страха: \n",
    "\n",
    "# Сообщает об опасности.\n",
    "\n",
    "# Побуждает убежать или спрятаться.\n",
    "\n",
    "\n",
    "# Гнев\n",
    "# Побуждает к активной защите от опасности.\n",
    "\n",
    "# Помогает преодолеть препятствие на пути к цели.\n",
    "\n",
    "# Придаёт сил и уверенности.\n",
    "\n",
    "# Причины печали:\n",
    "\n",
    "# Разлука и утрата.\n",
    "\n",
    "# Разочарование, крушение надежд.\n",
    "\n",
    "# Неудача в достижении цели.\n",
    "\n",
    "\n",
    "\n",
    "# Функции отвращения:\n",
    "\n",
    "# Регулирует дистанцию.\n",
    "\n",
    "# Устанавливает границы, в том числе в сексуальном поведении и гигиене.\n",
    "\n",
    "# Отвергает всё «чужеродное» в интеллектуальной, эмоциональной, ценностной и телесной, сферах.\n",
    "\n",
    "# Предупреждает попадание невкусного, чужеродного.\n",
    "\n",
    "# Помогает поддерживать гигиену, санитарные нормы.\n",
    "\n",
    "# Помогает избегать сомнительных ситуаций. \n",
    "\n",
    "\n",
    "\n",
    "# Функции радости:\n",
    "\n",
    "# Подтверждает доверительность в отношениях с близкими.\n",
    "\n",
    "# Подтверждает правильность выбранного пути.\n",
    "\n",
    "# Подтверждает удовлетворение потребностей.\n",
    "\n",
    "# Лечит — повышает иммунитет.\n",
    "\n",
    "# Мотивирует продолжать заниматься тем, чем мы занимаемся.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33eb7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_answer(text, gpt3_large, tokenizer):\n",
    "    \n",
    "    conatation = [' Функции радости:', \n",
    "                            'Функции отвращения:', \n",
    "                             'Причины печали:'  ,\n",
    "                              'Защита от опасности:' ]\n",
    "                  \n",
    "    answer = [' Очевидно у тебя все хорошо.)))' ,  \n",
    "               'Надо соблюдать дистанцию.',\n",
    "              ' Разочарование, крушение надежд.(((', \n",
    "               'Присядь и прикройся.']                     \n",
    " \n",
    "    triger = [' Подтверждает правильность выбранного пути.' ,  \n",
    "               'Устанавливает границы, в том числе в сексуальном поведении и гигиене.',\n",
    "              ' Неудача в достижении цели.', \n",
    "               ' Сообщает об опасности.']   \n",
    "\n",
    "    \n",
    "    answer_out, n = calculate_perplexity(text, gpt3_large, tokenizer, conatation, answer )\n",
    "  \n",
    "    #Продолжим разговор\n",
    "    answer_out_2 = generated_text(triger[n], gpt3_large, tokenizer)\n",
    "    \n",
    "    \n",
    "    return answer_out + ' ' + answer_out_2[len(triger[n]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063604d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_answer(\"Ваш чат никуда не годится\", gpt3_large, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facec546",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_answer(\"Прекрасный чат, зайду еще.\", gpt3_large, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f6e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "updater = Updater(my_token, use_context=True) # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text='Привет, давай пообщаемся?')\n",
    "    \n",
    "def textMessage(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=\"...\")\n",
    "    \n",
    "    answer = gen_answer(update.message.text, gpt3_large, tokenizer)\n",
    "    answer_gen =  generated_text(update.message.text, gpt3_large, tokenizer)\n",
    "    \n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=answer)\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=answer_gen)\n",
    "#     input_txt = preprocess_txt(update.message.text)\n",
    "#     vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "#     prediction = lr.predict(vect)\n",
    "    \n",
    "#     if prediction[0] == 1:\n",
    "#         vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "#         ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "#         for item in ft_index_shop_val:\n",
    "#             title, image = index_map_shop[item]\n",
    "#             context.bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
    "#         return\n",
    "#     vect_ft = embed_txt(input_txt, {}, 1)\n",
    "#     ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "#     if distances[0] > 2.5:\n",
    "#         print(distances[0])\n",
    "#         context.bot.send_message(chat_id=update.message.chat_id, text=\"Моя твоя не понимать\")\n",
    "#         return\n",
    "#     context.bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])\n",
    "        \n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35661ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
