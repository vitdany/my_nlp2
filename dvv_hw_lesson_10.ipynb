{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601165f6",
   "metadata": {},
   "source": [
    "## Задание\n",
    "Разобраться с моделькой перевода как она устроена\n",
    "запустить для перевода с русского на английский (при желании можно взять другие пары языков) два варианта с вниманием и без внимания\n",
    "оценить качество насколько корректно переводит "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e79dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27737284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-26 16:38:35--  http://www.manythings.org/anki/ita-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8011806 (7,6M) [application/zip]\n",
      "Saving to: ‘ita-eng.zip’\n",
      "\n",
      "ita-eng.zip         100%[===================>]   7,64M   150KB/s    in 2m 9s   \n",
      "\n",
      "2023-07-26 16:40:45 (60,8 KB/s) - ‘ita-eng.zip’ saved [8011806/8011806]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/ita-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feb834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ita-eng.zip\n",
      "  inflating: ita-eng/ita.txt         \n",
      "  inflating: ita-eng/_about.txt      \n"
     ]
    }
   ],
   "source": [
    "#Создаем папку и извлекаем туда файлы из архива\n",
    "!mkdir ita-eng\n",
    "!unzip ita-eng.zip -d ita-eng/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e598b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 50M\r\n",
      "drwxrwxr-x 2 msi msi 4,0K июл 26 16:45 .\r\n",
      "drwxrwxr-x 4 msi msi 4,0K июл 26 16:45 ..\r\n",
      "-rw-r--r-- 1 msi msi 1,5K апр  2 03:16 _about.txt\r\n",
      "-rw-r--r-- 1 msi msi  50M апр  2 03:16 ita.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./ita-eng/ -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48d386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем файл\n",
    "path_to_file = \"./ita-eng/ita.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16eedb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi.\tCiao!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #607364 (Cero)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#просмотр файла\n",
    "f = open(path_to_file)\n",
    "for line in f:\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeacf8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция препроцессинга\n",
    "def preprocess_sentence(w):\n",
    "  #переводим предложение к нижнему регистру и удалем начальные и конечные пробелы\n",
    "    w = w.lower().strip()\n",
    "\n",
    "  # отделяем пробелом слово и следующую за ним пунктуацию\n",
    "  # пример: \"he is a boy.\" => \"he is a boy .\"\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # все, кроме букв и знаков пунктуации, заменяем пробелом\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "  \n",
    "  #удаляем лишние пробелы в начале и конце\n",
    "    w = w.strip()\n",
    "\n",
    "  # создаем начало и конец последовательности\n",
    "  # теперь модель знает, где начинать и заканчивать предсказания\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e5a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> i can't go . <end>\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пример работы препроцессинга\n",
    "preprocess_sentence(\"I can't go.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a5e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Убираем акценты\n",
    "# 2. Очищаем предложения\n",
    "# 3. Возвращаем пары слов: [ENG, RUS]\n",
    "def create_dataset(path, num_examples):\n",
    "  #считываем строки файла\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  #каждую строку разделяем на пробелы, берем первые 2 слова, препроцессим их и возвращаем пару\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec6ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> hi . <end>\n",
      "<start> ciao ! <end>\n"
     ]
    }
   ],
   "source": [
    "#пример работы\n",
    "en, it = create_dataset(path_to_file, None)\n",
    "print(en[0])\n",
    "print(it[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a92eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364200, 364200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество данных в датасете\n",
    "len(en), len(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b6e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "      #токенизируем текст, отфильтвовываем пробелы\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "      #обновляем внутренний словарь на основе lang\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "      #преобразуем каждый элемент из lang в последовательность чисел\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "      #преобразуем тензор в матрицу (кол-во тензоров * max-длина), \n",
    "      #при этом короткие последовательности заполняем нулями сзади, а длинные -- обрезаем сзади\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e97ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "      # создаем очищенные анг (выходные), русские (входные) пары\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    #применяем токенизацию к каждому элементы из пары\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "851e2844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   1, 1217,   40, ...,    0,    0,    0],\n",
       "        [   1, 1217,    3, ...,    0,    0,    0],\n",
       "        [   1, 3633,   40, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,    4,   32, ...,    0,    0,    0],\n",
       "        [   1,    4,   32, ...,    0,    0,    0],\n",
       "        [   1,    4,   32, ...,    0,    0,    0]], dtype=int32),\n",
       " array([[   1, 1054,    3, ...,    0,    0,    0],\n",
       "        [   1, 1054,    3, ...,    0,    0,    0],\n",
       "        [   1,  346,   48, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,    5,    8, ...,    0,    0,    0],\n",
       "        [   1,    5,    8, ...,    0,    0,    0],\n",
       "        [   1,    5,    8, ...,    0,    0,    0]], dtype=int32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b619ce22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычисляем максимальную длину тензоров\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "max_length_targ, max_length_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d17fe3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Создаем тренировочные и валидационные датасеты\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# размеры датасетов\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5088fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция получения из токена текста (выводим токен и его индекс)\n",
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d83756c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "22 ----> noi\n",
      "195 ----> eravamo\n",
      "3330 ----> sedute\n",
      "6095 ----> sull'erba\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "18 ----> we\n",
      "525 ----> sat\n",
      "77 ----> on\n",
      "13 ----> the\n",
      "2065 ----> grass\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4aa024e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "#количество эпох\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 300\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "#из каждого элемента (input_tensor_train, target_tensor_train) создает тензор\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "#разбиваем датасет на батчи (списки по 64), удаляя последний неполный батч\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "623ba68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20) (64, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(20,), dtype=int32, numpy=\n",
       " array([  1,   4, 354,  45,  22,   3,   2,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  1,   5, 320,  83,  70,   3,   2,   0,   0,   0,   0], dtype=int32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "print(example_input_batch.shape, example_target_batch.shape)\n",
    "example_input_batch[0], example_target_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "577db60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=False,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "    #создаем тензор из нулей размера (батч, кол-во ячеек)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72b2ac1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# инициализитеруем начальное скрытое состояние (из нулей)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "# применяем энкодер к входному батчу и скрытому состоянию\n",
    "sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Форма выхода энкодера: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43b1dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        # x shape после прохождения через эмбеддинг == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # отправляем в GRU входные данные и скрытое состояние (от энкодера)\n",
    "        #выход GRU (batch_size, timesteps, units)\n",
    "        #размер возвращаемого внутреннего состояния (batch_size, units)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # x shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "953bf9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 6470]), TensorShape([64, 1024]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "#применяем декодер к случайному батчу из равномерного распределения (батч,1) и выходу энкодера\n",
    "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden)\n",
    "decoder_sample_x.shape, decoder_sample_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25ecbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#оптимизатор\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "#функция потерь\n",
    "def loss_function(real, pred):\n",
    "      #делаем инверсию значений сравнения каждого из real с нулем (возвращается true или false)\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "      #применяем функцию ошибок к реальным данным и предсказанным\n",
    "    loss_ = loss_object(real, pred)\n",
    "      #приводим тензор mask к новому типу loss_.dtype\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "      #умножаем loss_ на mask\n",
    "    loss_ *= mask\n",
    "      # возвращаем среднее значениe всех элементов\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdb17c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_nmt_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab15e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "  # перечисляем операции для автоматического дифференцирования\n",
    "    with tf.GradientTape() as tape:\n",
    "        #получаем выход encoder\n",
    "        enc_hidden = encoder(inp, enc_hidden)\n",
    "        #помещаем его в скрытое состояние decoder\n",
    "        dec_hidden = enc_hidden\n",
    "        #формируем вход декодера:\n",
    "                 # берем список длины батч из индексов тега <start> (1)\n",
    "                 # приписываем списку размерность 1 сзади (батч, 1)\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - выводим target в качестве следующего входа\n",
    "        for t in range(1, targ.shape[1]):\n",
    "          # помещаем enc_output в decoder\n",
    "            predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "          # считаем функцию потерь \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "          # используем teacher forcing (приписываем списку размерность 1 сзади)\n",
    "          #посылаем dec_input на вход декордера \n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    #переменные\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    #вычисляем градиенты loss по variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    #оптимизатор применяет подсчитанные градиенты\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c738d938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.4625\n",
      "Epoch 1 Batch 100 Loss 1.9428\n",
      "Epoch 1 Batch 200 Loss 1.6392\n",
      "Epoch 1 Batch 300 Loss 1.6486\n",
      "Epoch 1 Batch 400 Loss 1.4686\n",
      "Epoch 1 Batch 500 Loss 1.4769\n",
      "Epoch 1 Batch 600 Loss 1.2939\n",
      "Epoch 1 Batch 700 Loss 1.1403\n",
      "Epoch 1 Batch 800 Loss 1.1358\n",
      "Epoch 1 Batch 900 Loss 1.0490\n",
      "Epoch 1 Batch 1000 Loss 0.8544\n",
      "Epoch 1 Batch 1100 Loss 0.9026\n",
      "Epoch 1 Batch 1200 Loss 0.7800\n",
      "Epoch 1 Loss 1.3343\n",
      "Time taken for 1 epoch 1563.3809118270874 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.6104\n",
      "Epoch 2 Batch 100 Loss 0.6801\n",
      "Epoch 2 Batch 200 Loss 0.6570\n",
      "Epoch 2 Batch 300 Loss 0.5844\n",
      "Epoch 2 Batch 400 Loss 0.6403\n",
      "Epoch 2 Batch 500 Loss 0.5649\n",
      "Epoch 2 Batch 600 Loss 0.4772\n",
      "Epoch 2 Batch 700 Loss 0.5435\n",
      "Epoch 2 Batch 800 Loss 0.5850\n",
      "Epoch 2 Batch 900 Loss 0.3956\n",
      "Epoch 2 Batch 1000 Loss 0.4082\n",
      "Epoch 2 Batch 1100 Loss 0.3968\n",
      "Epoch 2 Batch 1200 Loss 0.4427\n",
      "Epoch 2 Loss 0.5396\n",
      "Time taken for 1 epoch 1708.7827017307281 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.2296\n",
      "Epoch 3 Batch 100 Loss 0.2444\n",
      "Epoch 3 Batch 200 Loss 0.2483\n",
      "Epoch 3 Batch 300 Loss 0.2629\n",
      "Epoch 3 Batch 400 Loss 0.2505\n",
      "Epoch 3 Batch 500 Loss 0.2708\n",
      "Epoch 3 Batch 600 Loss 0.3287\n",
      "Epoch 3 Batch 700 Loss 0.1876\n",
      "Epoch 3 Batch 800 Loss 0.2566\n",
      "Epoch 3 Batch 900 Loss 0.1787\n",
      "Epoch 3 Batch 1000 Loss 0.1877\n",
      "Epoch 3 Batch 1100 Loss 0.1809\n",
      "Epoch 3 Batch 1200 Loss 0.1790\n",
      "Epoch 3 Loss 0.2392\n",
      "Time taken for 1 epoch 1878.5032770633698 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.1437\n",
      "Epoch 4 Batch 100 Loss 0.1318\n",
      "Epoch 4 Batch 200 Loss 0.1263\n",
      "Epoch 4 Batch 300 Loss 0.1248\n",
      "Epoch 4 Batch 400 Loss 0.1089\n",
      "Epoch 4 Batch 500 Loss 0.1548\n",
      "Epoch 4 Batch 600 Loss 0.1445\n",
      "Epoch 4 Batch 700 Loss 0.1351\n",
      "Epoch 4 Batch 800 Loss 0.1147\n",
      "Epoch 4 Batch 900 Loss 0.1656\n",
      "Epoch 4 Batch 1000 Loss 0.1699\n",
      "Epoch 4 Batch 1100 Loss 0.1568\n",
      "Epoch 4 Batch 1200 Loss 0.0904\n",
      "Epoch 4 Loss 0.1331\n",
      "Time taken for 1 epoch 1860.757658958435 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0941\n",
      "Epoch 5 Batch 100 Loss 0.1051\n",
      "Epoch 5 Batch 200 Loss 0.0910\n",
      "Epoch 5 Batch 300 Loss 0.0994\n",
      "Epoch 5 Batch 400 Loss 0.0893\n",
      "Epoch 5 Batch 500 Loss 0.1174\n",
      "Epoch 5 Batch 600 Loss 0.0747\n",
      "Epoch 5 Batch 700 Loss 0.0906\n",
      "Epoch 5 Batch 800 Loss 0.1018\n",
      "Epoch 5 Batch 900 Loss 0.0849\n",
      "Epoch 5 Batch 1000 Loss 0.0927\n",
      "Epoch 5 Batch 1100 Loss 0.1295\n",
      "Epoch 5 Batch 1200 Loss 0.1160\n",
      "Epoch 5 Loss 0.0948\n",
      "Time taken for 1 epoch 1699.009652853012 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "  #инициализируем входное скрытое состояние (из нулей) размера (батч, кол-во рекуррентных ячеек)\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        #делаем шаг обучения. находим оштбку за этоху\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        #считаем ошибку\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7bd70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  #препоцессим предложение\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "      #разбиваем предложение по пробелам и составляем список индексов каждого слова\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "      #добиваем inputs нулями справа до максимальной длины входного текста\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                             maxlen=max_length_inp,\n",
    "                                                             padding='post')\n",
    "      #преобразуем inputs в тензор\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "      # инициализируем входной хидден из нулей размера (1, units)\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "      #подаем inputs и hidden в encoder\n",
    "    enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "      #инициализируем входной хидден декодера -- выходной хидден энкодера\n",
    "    dec_hidden = enc_hidden\n",
    "      #вход декодера -- список [индекс start] размера(1,1)\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "            #получаем выход декодера\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "   #заканчиваем на токене end\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence\n",
    "\n",
    "    # предсказанный predicted ID подаем обратно в декодер (размер (1,1))\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "661961dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция перевода\n",
    "def translate(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94082ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f17b1488bd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем последний checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b7a22e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> buon anno <end>\n",
      "Predicted translation: good luck . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('buon anno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa6998e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> il nuovo anno la vacanza migliore <end>\n",
      "Predicted translation: his glass was new . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('il nuovo anno è la vacanza migliore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e569ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Построение модели машинного перевода с вниманием <a id='section_4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55315e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98d809bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# инициализируем начальное скрытое состояние из нулей\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "#получаем выход энкодера и последнее скрытое состояние\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cff2cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        \n",
    "        #применяем к векторам скрытого состояния и выходов энкодера полносвязный слой (выход (batch_size, 1, units) и (batch_size, max_length, units))\n",
    "        #складываем полученные векторы, применяем к сумму тангенс выход (batch_size, max_length, units)\n",
    "        #проводим результат через dense слой выход (batch_size, max_length, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # получаем вероятностное распределение\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        # умножаем веса внимания умножаем на векторы значенй выход (batch_size, max_len, hidden size)\n",
    "        context_vector = attention_weights * values\n",
    "        #находим вдоль столбцов (batch_size, hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7b93f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "#создаем слой внимания\n",
    "attention_layer = BahdanauAttention(10)\n",
    "#передаем выход энкодера и его скрытое состояние\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad837424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       "array([[-0.01039974,  0.01132501,  0.00825692, ..., -0.00958878,\n",
       "         0.00119532, -0.01655166],\n",
       "       [-0.01042826,  0.00964835,  0.00532734, ..., -0.00972228,\n",
       "        -0.00051519, -0.01894228],\n",
       "       [-0.01123   ,  0.01341685,  0.00830989, ..., -0.0103007 ,\n",
       "         0.00067935, -0.02267005],\n",
       "       ...,\n",
       "       [-0.00649919,  0.01126624,  0.00489546, ..., -0.01016429,\n",
       "         0.00220477, -0.01421126],\n",
       "       [-0.00911233,  0.01078718,  0.00849943, ..., -0.01276174,\n",
       "         0.00123644, -0.01952188],\n",
       "       [-0.01151476,  0.01017414,  0.00644725, ..., -0.01050772,\n",
       "         0.00288545, -0.0202786 ]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "670f8e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 20, 1), dtype=float32, numpy=\n",
       "array([[[0.04990391],\n",
       "        [0.04898951],\n",
       "        [0.04895688],\n",
       "        ...,\n",
       "        [0.05036637],\n",
       "        [0.05036976],\n",
       "        [0.0503718 ]],\n",
       "\n",
       "       [[0.04992177],\n",
       "        [0.05051528],\n",
       "        [0.04980263],\n",
       "        ...,\n",
       "        [0.05038331],\n",
       "        [0.0503871 ],\n",
       "        [0.05038939]],\n",
       "\n",
       "       [[0.04968512],\n",
       "        [0.0502825 ],\n",
       "        [0.05026068],\n",
       "        ...,\n",
       "        [0.05015147],\n",
       "        [0.0501523 ],\n",
       "        [0.05015282]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.04995866],\n",
       "        [0.04890165],\n",
       "        [0.04957672],\n",
       "        ...,\n",
       "        [0.05042158],\n",
       "        [0.05042539],\n",
       "        [0.05042756]],\n",
       "\n",
       "       [[0.04969773],\n",
       "        [0.05043574],\n",
       "        [0.04946563],\n",
       "        ...,\n",
       "        [0.05016206],\n",
       "        [0.05016384],\n",
       "        [0.0501649 ]],\n",
       "\n",
       "       [[0.04983369],\n",
       "        [0.04925193],\n",
       "        [0.04963162],\n",
       "        ...,\n",
       "        [0.05029829],\n",
       "        [0.05030033],\n",
       "        [0.05030159]]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93747351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa7290c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        # используем слой внимания\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        # получаем выходы слоя внимания (из скрытого состояния и выхода энкодера)\n",
    "        # context_vector shape == (batch_size, hidden_size)\n",
    "        # attention_weights shape == (batch_size, max_len, 1)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        #соединяем выход эмбеддинга с вектором контекста и подаем навход RNN\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # (batch_size, 1, hidden_size) --> output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4849ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 6470)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "#применяем декодер к случайному батчу из равномерного распределения (батч,1) и выходам энкодера\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f289838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#оптимизатор\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c374ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_attention_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3c0ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_att(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        #получаем выходы encoder\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        #помещаем выходное скрытое состояние энкодера в скрытое состояние decoder\n",
    "        dec_hidden = enc_hidden\n",
    "        #формируем вход декодера:\n",
    "             # берем список длины батч из индексов тега <start>\n",
    "             # приписываем списку размерность 1 сзади\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - выводим target в качестве следующего входа\n",
    "        for t in range(1, targ.shape[1]):\n",
    "          # помещаем enc_output, dec_input, dec_hidden в decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            # считаем функцию потерь \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            # используем teacher forcing (приписываем списку размерность 1 сзади)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    #переменные\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    #вычисляем градиенты loss по variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    #оптимизатор применяет подсчитанные градиенты\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1321523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.5247\n",
      "Epoch 1 Batch 100 Loss 2.0470\n",
      "Epoch 1 Batch 200 Loss 1.6651\n",
      "Epoch 1 Batch 300 Loss 1.4963\n",
      "Epoch 1 Batch 400 Loss 1.2619\n",
      "Epoch 1 Batch 500 Loss 1.3404\n",
      "Epoch 1 Batch 600 Loss 1.0958\n",
      "Epoch 1 Batch 700 Loss 1.1726\n",
      "Epoch 1 Batch 800 Loss 0.9077\n",
      "Epoch 1 Batch 900 Loss 0.8766\n",
      "Epoch 1 Batch 1000 Loss 0.7555\n",
      "Epoch 1 Batch 1100 Loss 0.7215\n",
      "Epoch 1 Batch 1200 Loss 0.6012\n",
      "Epoch 1 Loss 1.2259\n",
      "Time taken for 1 epoch 3191.962040901184 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.5638\n",
      "Epoch 2 Batch 100 Loss 0.5872\n",
      "Epoch 2 Batch 200 Loss 0.5396\n",
      "Epoch 2 Batch 300 Loss 0.4634\n",
      "Epoch 2 Batch 400 Loss 0.3670\n",
      "Epoch 2 Batch 500 Loss 0.4463\n",
      "Epoch 2 Batch 600 Loss 0.4477\n",
      "Epoch 2 Batch 700 Loss 0.4090\n",
      "Epoch 2 Batch 800 Loss 0.3989\n",
      "Epoch 2 Batch 900 Loss 0.3572\n",
      "Epoch 2 Batch 1000 Loss 0.3483\n",
      "Epoch 2 Batch 1100 Loss 0.3668\n",
      "Epoch 2 Batch 1200 Loss 0.3647\n",
      "Epoch 2 Loss 0.4020\n",
      "Time taken for 1 epoch 2719.785792827606 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1967\n",
      "Epoch 3 Batch 100 Loss 0.1504\n",
      "Epoch 3 Batch 200 Loss 0.2053\n",
      "Epoch 3 Batch 300 Loss 0.3219\n",
      "Epoch 3 Batch 400 Loss 0.1918\n",
      "Epoch 3 Batch 500 Loss 0.1392\n",
      "Epoch 3 Batch 600 Loss 0.1761\n",
      "Epoch 3 Batch 700 Loss 0.1751\n",
      "Epoch 3 Batch 800 Loss 0.2098\n",
      "Epoch 3 Batch 900 Loss 0.2038\n",
      "Epoch 3 Batch 1000 Loss 0.1746\n",
      "Epoch 3 Batch 1100 Loss 0.1723\n",
      "Epoch 3 Batch 1200 Loss 0.1120\n",
      "Epoch 3 Loss 0.1889\n",
      "Time taken for 1 epoch 2718.3465733528137 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.1203\n",
      "Epoch 4 Batch 100 Loss 0.1219\n",
      "Epoch 4 Batch 200 Loss 0.0942\n",
      "Epoch 4 Batch 300 Loss 0.1250\n",
      "Epoch 4 Batch 400 Loss 0.1147\n",
      "Epoch 4 Batch 500 Loss 0.1421\n",
      "Epoch 4 Batch 600 Loss 0.0813\n",
      "Epoch 4 Batch 700 Loss 0.1291\n",
      "Epoch 4 Batch 800 Loss 0.1349\n",
      "Epoch 4 Batch 900 Loss 0.1297\n",
      "Epoch 4 Batch 1000 Loss 0.1303\n",
      "Epoch 4 Batch 1100 Loss 0.1016\n",
      "Epoch 4 Batch 1200 Loss 0.1243\n",
      "Epoch 4 Loss 0.1203\n",
      "Time taken for 1 epoch 2721.658442258835 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0792\n",
      "Epoch 5 Batch 100 Loss 0.0926\n",
      "Epoch 5 Batch 200 Loss 0.0737\n",
      "Epoch 5 Batch 300 Loss 0.0973\n",
      "Epoch 5 Batch 400 Loss 0.0679\n",
      "Epoch 5 Batch 500 Loss 0.0606\n",
      "Epoch 5 Batch 600 Loss 0.0815\n",
      "Epoch 5 Batch 700 Loss 0.0557\n",
      "Epoch 5 Batch 800 Loss 0.0534\n",
      "Epoch 5 Batch 900 Loss 0.0614\n",
      "Epoch 5 Batch 1000 Loss 0.0793\n",
      "Epoch 5 Batch 1100 Loss 0.1240\n",
      "Epoch 5 Batch 1200 Loss 0.1024\n",
      "Epoch 5 Loss 0.0908\n",
      "Time taken for 1 epoch 2674.726991176605 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    #инициализируем входное скрытое состояние (из нулей) размера (батч, кол-во рекуррентных ячеек)\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        #делаем шаг обучения\n",
    "        batch_loss = train_step_att(inp, targ, enc_hidden)\n",
    "        #считаем ошибку\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99e9e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_att(sentence):\n",
    "    #строим матрицу внимания из нулей размера (макс длина таргета, макс длина входа)  \n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    #препоцессим предложение\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    #разбиваем предложение по пробелам и составляем список индексов каждого слова\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    #добиваем inputs нулями справа до максимальной длины входного текста\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    #преобразуем inputs в тензор\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    # инициализируем входной хидден из нулей размера (1, units)\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    #подаем inputs и hidden в encoder\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    #инициализируем входной хидден декодера -- выходной хидден энкодера\n",
    "    dec_hidden = enc_hidden\n",
    "    #вход декодера -- список [индекс start] размера(1,1)  \n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        #получаем выход декодера\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "        # сохраняем веса внимания, чтобы позже визуализировать\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        #заканчиваем на токене end\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "    # предсказанный predicted ID подаем обратно в декодер (размер (1,1))\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e42a2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализация весов внимания\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "532c6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_att(sentence):\n",
    "    result, sentence, attention_plot = evaluate_att(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e25eb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f17b43b2f50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc9db3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> buone anno <end>\n",
      "Predicted translation: good news . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4967/956743606.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_4967/956743606.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate_att('buone anno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8595fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> lasciate mi cantare <end>\n",
      "Predicted translation: let me singing . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4967/956743606.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_4967/956743606.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate_att('lasciate mi cantare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a818ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
